<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Redis - hao</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="hao"><meta name="msapplication-TileImage" content="/img/2751710164138_.pic.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="hao"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content=""><meta property="og:type" content="blog"><meta property="og:title" content="hao"><meta property="og:url" content="https://jerryzhu1229.github.io/2024/03/14/Redis/"><meta property="og:site_name" content="hao"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/9fa26a74965efbf0f56b707a03bb9b7f.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/516738c4058cdf9109e40a7812ef4239.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/2fedbc9cd4cb7236c302d695686dd478.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/85f597f7851b90d6c78bb0d8e39690fc.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/a3b1f6235cf0587115b21312fe60289c.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/f46cbe347f65ded522f1cc3fd8dba549.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/c5fb0a602d4caaca37ff0357f05b0abf.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.drawio.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/6f0ab40396b7fc2c15e6f4487d3a0ad7-20230309232240301.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/337021a153944fd0f964ca834e34d0f2-20230309232243363.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/4eeef4dd1bedd2ffe0b84d4eaa0dbdea.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/98987d9417b2bab43087f45fc959d32a-20230309232253633.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/723d6c580c05400b3841bc69566dd61b-20230309232257343.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/d4cfac545377b54dd035c775603b4936.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309232301042.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/2b7231b6aabb9a9a2e2390ab3a280b2d.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/ea4f7e86baf2435af3999e5cd38b6a26.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/03eacec67cc58ff8d5819d0872ddd41e.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/e081b470870daeb763062bb873a4477e.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/2db4831516b9a8b79f833cf0593c1f12.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/26f88373d8454682b9e0c1d4fd1611b4.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/redis%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E6%98%A0%E5%B0%84%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB.jpg"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/Snipaste_2024-04-02_15-10-54.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/Snipaste_2024-04-02_15-22-42.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/惰性删除.jpg"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/定时删除流程.jpg"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/6e3db3ba2f829ddc14237f5c7c00e7ce-20230309232338149.png"><meta property="og:image" content="https://cdn.xiaolincoding.com//mysql/other/1cc7401143e79383ead96582ac11b615-20230309232407419.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/write-through.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/read-through.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/b7031182f770a7a5b3c82eaf749f53b0-20230309232834574.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/86b0046c2622b2c4bda697f9bc0f5b28.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/e2b8d2eb5536aa71664772457792ec40-20230309232851699.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/717343a0da7a1b05edab1d1cdf8f28e5.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/acb5f4e7ef24a524a53c39eb016f63d4-20230309232840753.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/1cc7401143e79383ead96582ac11b615.png"><meta property="og:image" content="https://jerryzhu1229.github.io/2024/03/14/pic/2a2ea2854bbc3ae8ae86d7da45fa32ee.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/a4440f0d572612e0832b903e4a62bd2b.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/v2-003cd3f411cfb65f60fdd31219ad4a9c_1440w.webp"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201509175.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201514331.png"><meta property="og:image" content="https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201528651.png"><meta property="og:image" content="https://img-blog.csdnimg.cn/20200723213200990.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70"><meta property="article:published_time" content="2024-03-14T13:51:05.000Z"><meta property="article:modified_time" content="2024-04-13T09:30:42.530Z"><meta property="article:author" content="Jerry Z"><meta property="article:tag" content="redis"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://jerryzhu1229.github.io/pic/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jerryzhu1229.github.io/2024/03/14/Redis/"},"headline":"Redis","image":["https://jerryzhu1229.github.io/pic/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg","https://jerryzhu1229.github.io/pic/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png","https://jerryzhu1229.github.io/pic/9fa26a74965efbf0f56b707a03bb9b7f.png","https://jerryzhu1229.github.io/pic/516738c4058cdf9109e40a7812ef4239.png","https://jerryzhu1229.github.io/pic/2fedbc9cd4cb7236c302d695686dd478.png","https://jerryzhu1229.github.io/pic/85f597f7851b90d6c78bb0d8e39690fc.png","https://jerryzhu1229.github.io/pic/a3b1f6235cf0587115b21312fe60289c.png","https://jerryzhu1229.github.io/pic/f46cbe347f65ded522f1cc3fd8dba549.png","https://jerryzhu1229.github.io/pic/c5fb0a602d4caaca37ff0357f05b0abf.png","https://jerryzhu1229.github.io/pic/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.png","https://jerryzhu1229.github.io/pic/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.drawio.png","https://jerryzhu1229.github.io/pic/6f0ab40396b7fc2c15e6f4487d3a0ad7-20230309232240301.png","https://jerryzhu1229.github.io/pic/337021a153944fd0f964ca834e34d0f2-20230309232243363.png","https://jerryzhu1229.github.io/pic/4eeef4dd1bedd2ffe0b84d4eaa0dbdea.png","https://jerryzhu1229.github.io/pic/98987d9417b2bab43087f45fc959d32a-20230309232253633.png","https://jerryzhu1229.github.io/pic/723d6c580c05400b3841bc69566dd61b-20230309232257343.png","https://jerryzhu1229.github.io/pic/d4cfac545377b54dd035c775603b4936.png","https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309232301042.png","https://jerryzhu1229.github.io/pic/2b7231b6aabb9a9a2e2390ab3a280b2d.png","https://jerryzhu1229.github.io/pic/ea4f7e86baf2435af3999e5cd38b6a26.png","https://jerryzhu1229.github.io/pic/03eacec67cc58ff8d5819d0872ddd41e.png","https://jerryzhu1229.github.io/pic/e081b470870daeb763062bb873a4477e.png","https://jerryzhu1229.github.io/pic/2db4831516b9a8b79f833cf0593c1f12.png","https://jerryzhu1229.github.io/pic/26f88373d8454682b9e0c1d4fd1611b4.png","https://jerryzhu1229.github.io/pic/redis%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E6%98%A0%E5%B0%84%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB.jpg","https://jerryzhu1229.github.io/pic/Snipaste_2024-04-02_15-10-54.png","https://jerryzhu1229.github.io/pic/Snipaste_2024-04-02_15-22-42.png","https://jerryzhu1229.github.io/2024/03/14/pic/惰性删除.jpg","https://jerryzhu1229.github.io/2024/03/14/pic/定时删除流程.jpg","https://jerryzhu1229.github.io/pic/6e3db3ba2f829ddc14237f5c7c00e7ce-20230309232338149.png","https://cdn.xiaolincoding.com//mysql/other/1cc7401143e79383ead96582ac11b615-20230309232407419.png","https://jerryzhu1229.github.io/pic/write-through.png","https://jerryzhu1229.github.io/pic/read-through.png","https://jerryzhu1229.github.io/2024/03/14/pic/b7031182f770a7a5b3c82eaf749f53b0-20230309232834574.png","https://jerryzhu1229.github.io/pic/86b0046c2622b2c4bda697f9bc0f5b28.png","https://jerryzhu1229.github.io/2024/03/14/pic/e2b8d2eb5536aa71664772457792ec40-20230309232851699.png","https://jerryzhu1229.github.io/2024/03/14/pic/717343a0da7a1b05edab1d1cdf8f28e5.png","https://jerryzhu1229.github.io/2024/03/14/pic/acb5f4e7ef24a524a53c39eb016f63d4-20230309232840753.png","https://jerryzhu1229.github.io/2024/03/14/pic/1cc7401143e79383ead96582ac11b615.png","https://jerryzhu1229.github.io/2024/03/14/pic/2a2ea2854bbc3ae8ae86d7da45fa32ee.png","https://jerryzhu1229.github.io/pic/a4440f0d572612e0832b903e4a62bd2b.png","https://jerryzhu1229.github.io/pic/v2-003cd3f411cfb65f60fdd31219ad4a9c_1440w.webp","https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70.png","https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201509175.png","https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201514331.png","https://jerryzhu1229.github.io/pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201528651.png"],"datePublished":"2024-03-14T13:51:05.000Z","dateModified":"2024-04-13T09:30:42.530Z","author":{"@type":"Person","name":"Jerry Z"},"publisher":{"@type":"Organization","name":"hao","logo":{"@type":"ImageObject","url":"https://jerryzhu1229.github.io/img/2751710164138_.pic.jpg"}},"description":""}</script><link rel="canonical" href="https://jerryzhu1229.github.io/2024/03/14/Redis/"><link rel="icon" href="/img/2751710164138_.pic.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.1.1"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/2751710164138_.pic.jpg" alt="hao" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">文章</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/categories/cs">计算机基础</a><a class="navbar-item" href="/categories/java">后端开发</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/jerryzhu1229"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-9-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-03-14T13:51:05.000Z" title="2024/3/14 21:51:05">2024-03-14</time>发表</span><span class="level-item"><time dateTime="2024-04-13T09:30:42.530Z" title="2024/4/13 17:30:42">2024-04-13</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/">中间件</a></span><span class="level-item">2 小时读完 (大约20843个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Redis</h1><div class="content"><html><head></head><body><h2 id="Redis-基础"><a href="#Redis-基础" class="headerlink" title="Redis 基础"></a>Redis 基础</h2><h3 id="什么是-Redis"><a href="#什么是-Redis" class="headerlink" title="什么是 Redis"></a>什么是 Redis</h3><ul>
<li>基于 c 开发</li>
<li>NoSQL 数据库</li>
<li>内存数据库，支持持久化</li>
<li>KY键值对数据</li>
</ul>
<h3 id="为什么要用-Redis-为什么要用缓存？"><a href="#为什么要用-Redis-为什么要用缓存？" class="headerlink" title="为什么要用 Redis/为什么要用缓存？"></a>为什么要用 Redis/为什么要用缓存？</h3><p>主要是因为 <strong>Redis 具备「高性能」和「高并发」两种特性</strong>。</p>
<p><strong>1、高性能</strong>：直接操作内存</p>
<p><strong>2、高并发</strong>：单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍</p>
<h3 id="Redis-单线程模式是怎样的？"><a href="#Redis-单线程模式是怎样的？" class="headerlink" title="Redis 单线程模式是怎样的？"></a>Redis 单线程模式是怎样的？</h3><p><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p>
<p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p>
<ul>
<li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，分别处理<strong>关闭文件</strong>、<strong>AOF 刷盘</strong>这两个任务；</li>
<li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来<strong>异步释放 Redis 内存</strong>，也就是 lazyfree 线程。</li>
</ul>
<p><img src="/../pic/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg" alt="多线程"></p>
<h3 id="Redis-采用单线程为什么还这么快？"><a href="#Redis-采用单线程为什么还这么快？" class="headerlink" title="Redis 采用单线程为什么还这么快？"></a>Redis 采用单线程为什么还这么快？</h3><ol>
<li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU。</li>
<li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li>
<li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</li>
</ol>
<h2 id="Redis-数据结构"><a href="#Redis-数据结构" class="headerlink" title="Redis 数据结构"></a>Redis 数据结构</h2><h3 id="Redis-数据类型以及使用场景分别是什么？"><a href="#Redis-数据类型以及使用场景分别是什么？" class="headerlink" title="Redis 数据类型以及使用场景分别是什么？"></a>Redis 数据类型以及使用场景分别是什么？</h3><p>常见的有五种数据类型：<strong>String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）</strong>。</p>
<p><img src="/../pic/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" alt="img"></p>
<p>Redis 五种数据类型的应用场景：</p>
<ul>
<li><p>String 类型的应用场景</p>
<ul>
<li><p><strong>需要存储常规数据的场景</strong></p>
<ul>
<li>举例：缓存 Session、Token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。</li>
<li>相关命令：<code>SET</code>、<code>GET</code>。</li>
</ul>
</li>
<li><p><strong>需要计数的场景</strong></p>
<ul>
<li>举例：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</li>
<li>相关命令：<code>SET</code>、<code>GET</code>、 <code>INCR</code>、<code>DECR</code> 。</li>
</ul>
</li>
<li><p><strong>分布式锁</strong></p>
<p>利用 <code>SETNX key value</code> 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）。</p>
</li>
</ul>
</li>
<li><p>List 类型的应用场景：</p>
<ul>
<li><strong>信息流展示</strong><ul>
<li>举例：最新文章、最新动态。</li>
<li>相关命令：<code>LPUSH</code>、<code>LRANGE</code>。</li>
</ul>
</li>
<li><strong>消息队列</strong>（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li>
</ul>
</li>
<li><p>Hash 类型：</p>
<ul>
<li><strong>对象数据存储场景</strong><ul>
<li>举例：用户信息、商品信息、文章信息、购物车信息。</li>
<li>相关命令：<code>HSET</code> （设置单个字段的值）、<code>HMSET</code>（设置多个字段的值）、<code>HGET</code>（获取单个字段的值）、<code>HMGET</code>（获取多个字段的值）。</li>
</ul>
</li>
</ul>
</li>
<li><p>Set 类型：</p>
<ul>
<li><p><strong>需要存放的数据不能重复的场景</strong></p>
<ul>
<li>举例：网站 UV 统计（数据量巨大的场景还是 <code>HyperLogLog</code>更适合一些）、文章点赞、动态点赞等场景。</li>
<li>相关命令：<code>SCARD</code>（获取集合数量） 。</li>
</ul>
</li>
<li><p><strong>需要获取多个数据源交集、并集和差集的场景</strong></p>
<ul>
<li>举例：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等场景。</li>
<li>相关命令：<code>SINTER</code>（交集）、<code>SINTERSTORE</code> （交集）、<code>SUNION</code> （并集）、<code>SUNIONSTORE</code>（并集）、<code>SDIFF</code>（差集）、<code>SDIFFSTORE</code> （差集）。</li>
</ul>
</li>
<li><p><strong>需要随机获取数据源中的元素的场景</strong></p>
<ul>
<li>举例：抽奖系统、随机点名等场景。</li>
<li>相关命令：<code>SPOP</code>（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、<code>SRANDMEMBER</code>（随机获取集合中的元素，适合允许重复中奖的场景）。</li>
</ul>
</li>
</ul>
</li>
<li><p>Zset 类型：</p>
<ul>
<li><p><strong>需要随机获取数据源中的元素根据某个权重进行排序的场景</strong></p>
<ul>
<li>举例：各种排行榜比如直播间送礼物的<strong>排行榜</strong>、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li>
<li>相关命令：<code>ZRANGE</code> (从小到大排序)、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>特殊数据类型</p>
<ul>
<li><p>BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</p>
</li>
<li><p>HyperLogLog（2.8 版新增）：</p>
<ul>
<li><strong>数量量巨大（百万、千万级别以上）的计数场景</strong><ul>
<li>举例：热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计、</li>
<li>相关命令：<code>PFADD</code>、<code>PFCOUNT</code> 。</li>
</ul>
</li>
</ul>
</li>
<li><p>GEO（3.2 版新增）：</p>
<ul>
<li><strong>需要管理使用地理空间数据的场景</strong><ul>
<li>举例：附近的人，滴滴叫车。</li>
<li>相关命令: <code>GEOADD</code>、<code>GEORADIUS</code>、<code>GEORADIUSBYMEMBER</code> 。</li>
</ul>
</li>
</ul>
</li>
<li><p>Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。</p>
</li>
</ul>
<h3 id="常见的-Redis-数据类型是怎么实现？"><a href="#常见的-Redis-数据类型是怎么实现？" class="headerlink" title="常见的 Redis 数据类型是怎么实现？"></a>常见的 Redis 数据类型是怎么实现？</h3><p><img src="/../pic/9fa26a74965efbf0f56b707a03bb9b7f.png" alt="redis常见数据类型"></p>
<h4 id="String-类型内部实现"><a href="#String-类型内部实现" class="headerlink" title="String 类型内部实现"></a>String 类型内部实现</h4><p>String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。</p>
<p><img src="/../pic/516738c4058cdf9109e40a7812ef4239.png" alt="sds 数据结构"></p>
<ul>
<li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li>
<li>**SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。</li>
<li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li>
</ul>
<h4 id="List-类型内部实现"><a href="#List-类型内部实现" class="headerlink" title="List 类型内部实现"></a>List 类型内部实现</h4><p>List 类型的底层数据结构是由<strong>双向链表或压缩列表</strong>实现的：</p>
<ul>
<li>如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li>
<li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li>
</ul>
<p>但是<strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong>。</p>
<h4 id="Hash-类型内部实现"><a href="#Hash-类型内部实现" class="headerlink" title="Hash 类型内部实现"></a>Hash 类型内部实现</h4><p>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p>
<ul>
<li>如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li>
<li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的底层数据结构。</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong>。</p>
<p><img src="/../pic/2fedbc9cd4cb7236c302d695686dd478.png" alt="hash 数据类型"></p>
<p>实际redis 定义的dict结构下有两个哈希表dictht，一个是用来存数据的，另一个是用来 rehash 的。每个哈希表是一个数组，每一个元素是指向「哈希表节点」的指针。</p>
<p><strong>rehash 的触发条件</strong></p>
<p><img src="/../pic/85f597f7851b90d6c78bb0d8e39690fc.png" alt="负载因子公式"></p>
<p>若负载因子&gt;=1，若没有执行bgsave 或者 bgrewriteaof，才会立即进行 rehash</p>
<p>若负载因子&gt;=5，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。</p>
<p><strong>rehash</strong></p>
<p>dict 下的两个 dictht 哈希表，正常情况下只会往「哈希表 1」中插入数据，「哈希表 2」是不会分配空间。</p>
<p>当触发了 rehash 条件时：</p>
<ul>
<li>给「哈希表 2」分配比「哈希表 1」 大一倍的空间</li>
<li>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。</li>
</ul>
<p>缺点：当数据量特别大时，会造成redis 长时间的阻塞</p>
<p><strong>渐进 rehash</strong></p>
<p>数据从一次性迁移完成，变成分批迁移</p>
<p>当触发了 rehash 条件时：</p>
<ul>
<li>给「哈希表 2」分配比「哈希表 1」 大一倍的空间</li>
<li>在 rehash 期间，每次对于哈希表元素的新增、修改和查找操作时，redis除了执行对应操作之外，还会<strong>将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上</strong>；</li>
<li>随着对哈希表的请求操作的增加，最后完成数据的迁移</li>
</ul>
<p>在 rehash 时需要满足：</p>
<ul>
<li><p>查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p>
</li>
<li><p>新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。</p>
</li>
</ul>
<h4 id="Set-类型内部实现"><a href="#Set-类型内部实现" class="headerlink" title="Set 类型内部实现"></a>Set 类型内部实现</h4><p>Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：</p>
<ul>
<li>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li>
<li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li>
</ul>
<p><strong>整数集合</strong></p>
<p>本质是一块连续的内存区域</p>
<figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> {</span></span><br><span class="line">    <span class="comment">//编码方式</span></span><br><span class="line">    <span class="type">uint32_t</span> encoding;</span><br><span class="line">    <span class="comment">//集合包含的元素数量</span></span><br><span class="line">    <span class="type">uint32_t</span> length;</span><br><span class="line">    <span class="comment">//保存元素的数组</span></span><br><span class="line">    <span class="type">int8_t</span> contents[];</span><br><span class="line">} intset;</span><br></pre></td></tr></tbody></table></figure>

<p>根据 encoding 来决定 contents[]的真正类型</p>
<p>encoding 有三种 int16_t、 int32_t、 int64_t</p>
<p><strong>升级操作</strong></p>
<p>假如一开始都是存 int16，然后加入一个只有 int32 才能存的数，那么就会触发升级操作。</p>
<p>流程包括：</p>
<ol>
<li>数组扩充</li>
<li>将元素从后向前转换类型放在对应位置</li>
</ol>
<p>好处：</p>
<p>节省内存资源</p>
<p>缺点：</p>
<p>但不支持降级操作</p>
<h4 id="ZSet-类型内部实现（重要）"><a href="#ZSet-类型内部实现（重要）" class="headerlink" title="ZSet 类型内部实现（重要）"></a>ZSet 类型内部实现（重要）</h4><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p>
<ul>
<li>当有序集合对象同时满足以下两个条件时，使用 ziplist：<ol>
<li>ZSet 保存的键值对数量少于 128 个；</li>
<li>每个元素的长度小于 64 字节。</li>
</ol>
</li>
<li>如果不满足上述两个条件，那么使用 skiplist 。</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p>
<h3 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a>底层数据结构</h3><h4 id="ziplist"><a href="#ziplist" class="headerlink" title="ziplist"></a>ziplist</h4><p>压缩列表是 Redis 为了节约内存而开发的，它是<strong>由连续内存块组成的顺序型数据结构</strong>，有点类似于数组。</p>
<p><img src="/../pic/a3b1f6235cf0587115b21312fe60289c.png" alt="ziplist"></p>
<p>压缩列表在表头有三个字段：</p>
<ul>
<li><em><strong>zlbytes</strong></em>，记录整个压缩列表占用对内存字节数；</li>
<li><em><strong>zltail</strong></em>，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；</li>
<li><em><strong>zllen</strong></em>，记录压缩列表包含的节点数量；</li>
<li><em><strong>zlend</strong></em>，标记压缩列表的结束点，固定值 0xFF（十进制255）。</li>
</ul>
<p>压缩列表节点包含三部分内容：</p>
<ul>
<li><em><strong>prevlen</strong></em>，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；</li>
<li><em><strong>encoding</strong></em>，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。</li>
<li><em><strong>data</strong></em>，记录了当前节点的实际数据，类型和长度都由 <code>encoding</code> 决定；</li>
</ul>
<p>当我们往压缩列表中插入数据时，压缩列表就会根据数据类型是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，<strong>这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的</strong>。</p>
<p><strong>缺陷：</strong>存在<strong>连锁更新</strong>问题。多个连续的长度为 250～253 的元素，当插入一个长度大于等于 254 的元素时，会让后面的元素的 prevlen 从之前的 1 字节变成 5 字节，而不断发生内存重新分配的问题。</p>
<h4 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h4><p>quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表。</p>
<p><img src="/../pic/f46cbe347f65ded522f1cc3fd8dba549.png" alt="quicklist"></p>
<p>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。</p>
<h4 id="listpack"><a href="#listpack" class="headerlink" title="listpack"></a>listpack</h4><p>quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。</p>
<p>因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。</p>
<p>于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p>
<p><img src="/../pic/c5fb0a602d4caaca37ff0357f05b0abf.png" alt="listpack"></p>
<p>listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。</p>
<p>Listpack entry主要包含三个方面内容：</p>
<ul>
<li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li>
<li>data，实际存放的数据；</li>
<li>len，encoding+data的总长度；</li>
</ul>
<p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
<h3 id="为什么用跳表实现有序集合"><a href="#为什么用跳表实现有序集合" class="headerlink" title="为什么用跳表实现有序集合"></a>为什么用跳表实现有序集合</h3><p>zset结构体中有两个数据结构：跳表、哈希表。好处是既能进行高效的范围查询，又能进行高效的单点查询</p>
<p>或者是在数据量少的时候用压缩列表</p>
<h4 id="跳表的建立"><a href="#跳表的建立" class="headerlink" title="跳表的建立"></a>跳表的建立</h4><p>跳表可以理解为在原始链表基础上，建立「多层」有序链表，将增删改查的时间复杂度变为O(log n)。</p>
<p><img src="/../pic/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.png" alt="跳表"></p>
<figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> {</span></span><br><span class="line">  	<span class="comment">//跳表的头尾节点，便于在O(1)时间复杂度内访问跳表的头节点和尾节点；</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span></span><br><span class="line">  	<span class="comment">//跳表的长度，便于在O(1)时间复杂度获取跳表节点的数量；</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> length;</span><br><span class="line">  	<span class="comment">//跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；</span></span><br><span class="line">    <span class="type">int</span> level;</span><br><span class="line">} zskiplist;</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">typedef struct zskiplistNode {</span><br><span class="line">    <span class="comment">//Zset 对象的元素值</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//元素权重值</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    struct zskiplistLevel {</span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line">        unsigned <span class="type">long</span> span;</span><br><span class="line">    } level[];</span><br><span class="line">} zskiplistNode;</span><br></pre></td></tr></tbody></table></figure>



<h4 id="跳表节点查询"><a href="#跳表节点查询" class="headerlink" title="跳表节点查询"></a>跳表节点查询</h4><p>查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 <strong>SDS 类型的元素</strong>和<strong>元素的权重</strong>来进行判断，判断是走这一层下一个节点还是走当前节点的下一层的下一个节点，共有两个判断条件：</p>
<ul>
<li>如果下一个节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。</li>
<li>如果下一个节点的权重「等于」要查找的权重时，并且下一个节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。</li>
</ul>
<p>如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。</p>
<p><img src="/../pic/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.drawio.png" alt="3层跳表-跨度"></p>
<h4 id="跳表节点层数设置"><a href="#跳表节点层数设置" class="headerlink" title="跳表节点层数设置"></a>跳表节点层数设置</h4><p>理想情况是每一层索引是下一层元素个数的二分之一。</p>
<p>Redis 则采用一种巧妙的方法是，<strong>跳表在创建节点的时候，随机生成每个节点的层数</strong>，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。</p>
<p>具体的做法是，<strong>跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</strong>。</p>
<p>这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。</p>
<p>虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，但是其实<strong>如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点</strong>。</p>
<h4 id="和其余三种数据结构的比较"><a href="#和其余三种数据结构的比较" class="headerlink" title="和其余三种数据结构的比较"></a>和其余三种数据结构的比较</h4><p><strong>平衡树 vs 跳表</strong></p>
<p>平衡条件必须满足（所有节点的左右子树高度差不超过 1，即平衡因子为范围为 <code>[-1,1]</code>）。平衡树的插入、删除和查询的时间复杂度和跳表一样都是 **O(log n)**。</p>
<p>对于范围查询来说，它也可以通过中序遍历的方式达到和跳表一样的效果。但是它的每一次插入或者删除操作都需要保证整颗树左右节点的绝对平衡，<strong>只要不平衡就要通过旋转操作来保持平衡，这个过程是比较耗时的</strong>。</p>
<p><strong>红黑树 vs 跳表</strong></p>
<p><strong>红黑树查询性能略微逊色于 AVL 树，但插入和删除效率更高。</strong>红黑树的插入、删除和查询的时间复杂度和跳表一样都是 **O(log n)**。</p>
<p>红黑树是一个<strong>黑平衡树</strong>，即从任意节点到另外一个叶子节点，它所经过的黑节点是一样的。当对它进行插入操作时，需要通过旋转和染色（红黑变换）来保证黑平衡。不过，相较于 AVL 树为了维持平衡的开销要小一些。</p>
<p>相比较于红黑树来说，<strong>跳表的实现也更简单一些</strong>。并且，<strong>按照区间来查找数据这个操作，红黑树的效率没有跳表高</strong>。</p>
<blockquote>
<p>红黑树（Red-Black Tree）是一种自平衡的二叉查找树，它在每个节点上增加了一个额外的属性，即节点的颜色，可以是红色或黑色。红黑树具有以下特点：</p>
<ol>
<li><strong>节点颜色</strong>：每个节点要么是红色，要么是黑色。</li>
<li><strong>根节点和叶子节点</strong>：根节点是黑色的，叶子节点（NIL节点）是黑色的。</li>
<li><strong>颜色约束</strong>：红色节点的子节点必须是黑色的。换句话说，不能有两个相邻的红色节点，即红色节点不能连续存在。</li>
<li><strong>黑色高度约束</strong>：从任一节点到其每个叶子节点的所有路径都包含相同数目的黑色节点，这个数目称为黑色高度。</li>
<li><strong>平衡性</strong>：保证了树的黑色高度相对平衡，确保了最长路径不超过最短路径的两倍。</li>
</ol>
<p>通过这些约束，红黑树能够在插入和删除节点时自动调整结构，以保持这些约束，从而保证了树的平衡性，使得查找、插入和删除等操作的最坏情况时间复杂度都是 O(log n)。</p>
</blockquote>
<p><strong>B+树 vs 跳表</strong></p>
<p>内存数据库它不可能存储大量的数据，所以对于索引不需要通过 B+树这种方式进行维护。</p>
<p>使用跳表实现 zset 时相较前者来说更简单一些，在进行插入时只需通过索引将数据插入到链表中合适的位置再随机维护一定高度的索引即可，也不需要像 B+树那样插入时发现失衡时还需要<strong>对节点分裂与合并</strong>。</p>
<p>总结：</p>
<ul>
<li><strong>从内存占用上来比较，跳表比平衡树更灵活一些</strong>。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li>
<li><strong>在做范围查找的时候，跳表比平衡树操作要简单</strong>。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li>
<li><strong>从算法实现难度上来比较，跳表比平衡树要简单得多</strong>。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速</li>
</ul>
<h2 id="Redis-持久化"><a href="#Redis-持久化" class="headerlink" title="Redis 持久化"></a>Redis 持久化</h2><p>Redis 共有三种数据持久化的方式：</p>
<ul>
<li><strong>AOF （append only file）日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</li>
<li><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</li>
<li><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；</li>
</ul>
<h3 id="AOF-日志是如何实现的？"><a href="#AOF-日志是如何实现的？" class="headerlink" title="AOF 日志是如何实现的？"></a>AOF 日志是如何实现的？</h3><p>Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。</p>
<p><img src="/../pic/6f0ab40396b7fc2c15e6f4487d3a0ad7-20230309232240301.png" alt="aof 流程"></p>
<p><img src="/../pic/337021a153944fd0f964ca834e34d0f2-20230309232243363.png" alt="img"></p>
<p>「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。</p>
<h4 id="为什么先执行命令，再把数据写入日志呢？"><a href="#为什么先执行命令，再把数据写入日志呢？" class="headerlink" title="为什么先执行命令，再把数据写入日志呢？"></a>为什么先执行命令，再把数据写入日志呢？</h4><p>好处：</p>
<ol>
<li><p><strong>避免额外的检查开销</strong>（语法检查）</p>
</li>
<li><p><strong>不会阻塞当前写操作命令的执行</strong></p>
</li>
</ol>
<p>风险：</p>
<ol>
<li><strong>数据可能会丢失</strong></li>
<li><strong>可能阻塞后续操作</strong></li>
</ol>
<h4 id="AOF-写回策略有几种？"><a href="#AOF-写回策略有几种？" class="headerlink" title="AOF 写回策略有几种？"></a>AOF 写回策略有几种？</h4><p>Redis 写入 AOF 日志的过程</p>
<p><img src="/../pic/4eeef4dd1bedd2ffe0b84d4eaa0dbdea.png" alt="img"></p>
<ol>
<li>redis 执行完写操作后，将命令追加到 <code>server.aof_buf</code> 缓冲区</li>
<li>然后通过 write()系统调用将缓冲区的内容写到内核缓冲区page cache，等待内核将数据写入硬盘</li>
<li>具体内核缓冲区什么时候写入硬盘有三种写回策略</li>
</ol>
<p><img src="/../pic/98987d9417b2bab43087f45fc959d32a-20230309232253633.png" alt="img"></p>
<p>这三种策略只是在控制 <code>fsync()</code> 函数的调用时机。</p>
<h4 id="AOF-日志过大，会触发什么机制？"><a href="#AOF-日志过大，会触发什么机制？" class="headerlink" title="AOF 日志过大，会触发什么机制？"></a>AOF 日志过大，会触发什么机制？</h4><p>Redis 为了避免 AOF 文件越写越大，提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。</p>
<p><img src="/../pic/723d6c580c05400b3841bc69566dd61b-20230309232257343.png" alt="在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件"></p>
<p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p>
<p>为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去？<strong>如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染</strong>，可能无法用于恢复使用。</p>
<h4 id="重写-AOF-日志的过程是怎样的？"><a href="#重写-AOF-日志的过程是怎样的？" class="headerlink" title="重写 AOF 日志的过程是怎样的？"></a>重写 AOF 日志的过程是怎样的？</h4><p>redis 的<strong>重写 AOF 过程是由后台==子进程== bgrewriteaof 来完成的</strong></p>
<p>好处：</p>
<ul>
<li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；</li>
<li>子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过<strong>加锁</strong>来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以<strong>只读</strong>的方式，而当父子进程任意一方修改了该共享内存，就会发生==「写时复制（Copy On Write）」==，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</li>
</ul>
<blockquote>
<p>写时复制：</p>
<p>主进程在通过 <code>fork</code> 系统调用生成子进程时，操作系统会把主进程的「<strong>页表</strong>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</p>
<p><img src="/../pic/d4cfac545377b54dd035c775603b4936.png" alt="img"></p>
<p>这样一来，子进程就共享了父进程的物理内存数据了，这样能够<strong>节约物理内存资源</strong>，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</p>
<p>不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发<strong>写保护中断</strong>，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行<strong>物理内存的复制</strong>，并重新设置其内存映射关系，将父子进程的内存读写权限设置为<strong>可读写</strong>，最后才会对内存进行写操作，这个过程被称为「**写时复制(*Copy On Write*)**」。</p>
<p>写时复制顾名思义，<strong>在发生写操作的时候，操作系统才会去复制物理内存</strong>，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。</p>
</blockquote>
<p><strong>但是重写过程中，主进程依然可以正常处理命令</strong>，那问题来了，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，那么会发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？</p>
<p>为了解决这种数据不一致问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。</p>
<p><img src="/../pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309232301042.png" alt="img"></p>
<p>当子进程完成 AOF 重写工作（<em><strong>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</strong></em>）后，会向主进程发送一条信号，主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p>
<ul>
<li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li>
<li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li>
</ul>
<h3 id="RDB-快照是如何实现的呢？"><a href="#RDB-快照是如何实现的呢？" class="headerlink" title="RDB 快照是如何实现的呢？"></a>RDB 快照是如何实现的呢？</h3><p><strong>AOF 缺点</strong>：因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的<strong>恢复操作缓慢</strong>。</p>
<p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。</p>
<p>因此在 Redis 恢复数据时， <strong>RDB 恢复数据的效率会比 AOF 高些</strong>，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p>
<h4 id="RDB-做快照时会阻塞线程吗？"><a href="#RDB-做快照时会阻塞线程吗？" class="headerlink" title="RDB 做快照时会阻塞线程吗？"></a>RDB 做快照时会阻塞线程吗？</h4><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：</p>
<ul>
<li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li>
<li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li>
</ul>
<h4 id="RDB-快照缺点"><a href="#RDB-快照缺点" class="headerlink" title="RDB 快照缺点"></a>RDB 快照缺点</h4><p>Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个<strong>比较重的操作</strong>，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。</p>
<h4 id="RDB-在执行快照的时候，数据能修改吗？"><a href="#RDB-在执行快照的时候，数据能修改吗？" class="headerlink" title="RDB 在执行快照的时候，数据能修改吗？"></a>RDB 在执行快照的时候，数据能修改吗？</h4><p>可以的，执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong></p>
<p>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。</p>
<p>如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。</p>
<p>存在问题 ：</p>
<ol>
<li><p>在 RDB 执行快照的时候，主线程对内存的修改只能到下一次 RDB 的时候才能持久化。假如在完成本次 RDB 快照后 redis 宕机，就会丢失在快照期间修改的数据</p>
</li>
<li><p>另外，写时复制的时候会出现这么个极端的情况。</p>
<p>在 Redis 执行 RDB 持久化期间，刚 fork 时，主进程和子进程共享同一物理内存，但是途中主进程处理了写操作，修改了共享内存，于是当前被修改的数据的物理内存就会被复制一份。</p>
<p>那么极端情况下，<strong>如果所有的共享内存都被修改，则此时的内存占用是原先的 2 倍。</strong></p>
<p>所以，针对写操作多的场景，我们要留意下快照过程中内存的变化，防止内存被占满了。</p>
</li>
</ol>
<h3 id="为什么会有混合持久化？"><a href="#为什么会有混合持久化？" class="headerlink" title="为什么会有混合持久化？"></a>为什么会有混合持久化？</h3><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。</p>
<p>AOF 优点是丢失数据少，但是数据恢复不快。</p>
<p>AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p>
<p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p>
<p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。</p>
<p><strong>混合持久化优点：</strong></p>
<ul>
<li>混合持久化工作在 <strong>AOF 日志重写过程</strong>，==既保证了 Redis 重启速度，又降低数据丢失风险。==</li>
</ul>
<p><strong>混合持久化缺点：</strong></p>
<ul>
<li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的<strong>可读性差</strong>；</li>
<li><strong>兼容性差</strong>，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li>
</ul>
<h2 id="Redis-集群-高可用"><a href="#Redis-集群-高可用" class="headerlink" title="Redis 集群/高可用"></a>Redis 集群/高可用</h2><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p>主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。</p>
<p>主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。</p>
<p><img src="/../pic/2b7231b6aabb9a9a2e2390ab3a280b2d.png"></p>
<p>也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。</p>
<p>主从复制共有三种模式：<strong>全量复制、基于长连接的命令传播、增量复制</strong>。</p>
<ol>
<li><p>主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。</p>
</li>
<li><p>第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。</p>
</li>
<li><p>如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。</p>
<p>如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。</p>
</li>
</ol>
<h4 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h4><ul>
<li>第一阶段是建立链接、协商同步【发送主服务器的 runID 和复制进度 offset】；</li>
<li>第二阶段是主服务器同步数据给从服务器【bgsave 生成 RDB】；</li>
<li>第三阶段是主服务器发送新写操作命令给从服务器【将第二阶段期间新增的写命令存放在 replication buffer，然后发送给从服务器执行】。</li>
</ul>
<p><img src="/../pic/ea4f7e86baf2435af3999e5cd38b6a26.png"></p>
<h4 id="基于长连接的命令传播"><a href="#基于长连接的命令传播" class="headerlink" title="基于长连接的命令传播"></a>基于长连接的命令传播</h4><p><img src="/../pic/03eacec67cc58ff8d5819d0872ddd41e.png"></p>
<h4 id="增量复制"><a href="#增量复制" class="headerlink" title="增量复制"></a>增量复制</h4><p>主从服务器在完成第一次同步后，就会基于长连接进行命令传播。</p>
<p>若网络中断则会使用<strong>增量复制</strong>重新同步。</p>
<p><img src="/../pic/e081b470870daeb763062bb873a4477e.png"></p>
<p>主要有三个步骤：</p>
<ul>
<li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；</li>
<li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li>
<li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令</li>
</ul>
<p><strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong></p>
<p>答案藏在这两个东西里：</p>
<ul>
<li><strong>repl_backlog_buffer</strong>，是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li>
<li><strong>replication offset</strong>，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「<em>写</em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「<em>读</em>」到的位置。</li>
</ul>
<p><img src="/../pic/2db4831516b9a8b79f833cf0593c1f12.png"></p>
<h4 id="怎么判断-Redis-某个节点是否正常工作？"><a href="#怎么判断-Redis-某个节点是否正常工作？" class="headerlink" title="怎么判断 Redis 某个节点是否正常工作？"></a>怎么判断 Redis 某个节点是否正常工作？</h4><p>基本都是<strong>通过互相的 ping-pong 心态检测机制</strong>，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。</p>
<p>Redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别：</p>
<ul>
<li>Redis 主节点默认每隔 10 秒对从节点发送 <strong>ping</strong> 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。</li>
<li>Redis 从节点每隔 1 秒发送 <strong>replconf ack{offset}</strong> 命令，给主节点上报自身当前的复制偏移量，目的是为了：<ul>
<li>实时监测主从节点网络状态；</li>
<li>上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。</li>
</ul>
</li>
</ul>
<h4 id="主从复制架构中，过期key如何处理？"><a href="#主从复制架构中，过期key如何处理？" class="headerlink" title="主从复制架构中，过期key如何处理？"></a>主从复制架构中，过期key如何处理？</h4><p>主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。</p>
<h4 id="Redis-是同步复制还是异步复制？"><a href="#Redis-是同步复制还是异步复制？" class="headerlink" title="Redis 是同步复制还是异步复制？"></a>Redis 是同步复制还是异步复制？</h4><p>Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。</p>
<h4 id="主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？"><a href="#主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？" class="headerlink" title="主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？"></a>主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</h4><ul>
<li>出现的阶段不一样：<ul>
<li>repl backlog buffer 是在增量复制阶段出现，<strong>一个主节点只分配一个 repl backlog buffer</strong>；</li>
<li>replication buffer 是在全量复制阶段和增量复制阶段都会出现，<strong>主节点会给每个新连接的从节点，分配一个 replication buffer</strong>；</li>
</ul>
</li>
<li>这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：<ul>
<li>当 repl backlog buffer 满了，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>;</li>
<li>当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，<strong>重新开始全量复制</strong>。</li>
</ul>
</li>
</ul>
<h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><p>在使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。</p>
<p>为了解决这个问题，Redis 增加了哨兵模式（<strong>Redis Sentinel</strong>），因为哨兵模式做到了可以监控主从服务器，并且==提供主从节点故障转移==的功能。</p>
<p><img src="/../pic/26f88373d8454682b9e0c1d4fd1611b4.png"></p>
<h3 id="Redis-Cluster切片集群模式"><a href="#Redis-Cluster切片集群模式" class="headerlink" title="Redis Cluster切片集群模式"></a>Redis Cluster切片集群模式</h3><p>当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 <strong>Redis 切片集群</strong>（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。</p>
<h4 id="Redis-Cluster-是如何分片的"><a href="#Redis-Cluster-是如何分片的" class="headerlink" title="Redis Cluster 是如何分片的?"></a><strong>Redis Cluster 是如何分片的?</strong></h4><p>Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，<strong>一个切片集群共有 16384 【2^14】个哈希槽</strong>，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：</p>
<ul>
<li>根据键值对的 key，按照 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">CRC16 算法 (opens new window)</a>计算一个 16 bit 的值。</li>
<li>再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</li>
</ul>
<p>接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：</p>
<ul>
<li><strong>平均分配：</strong> 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。</li>
<li><strong>手动分配：</strong> 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。</li>
</ul>
<p>为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。</p>
<p><img src="/../pic/redis%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E6%98%A0%E5%B0%84%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB.jpg"></p>
<p>上图中的切片集群一共有 2 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。</p>
<figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h <span class="number">192.168</span><span class="number">.1</span><span class="number">.10</span> –p <span class="number">6379</span> cluster addslots <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">redis-cli -h <span class="number">192.168</span><span class="number">.1</span><span class="number">.11</span> –p <span class="number">6379</span> cluster addslots <span class="number">2</span>,<span class="number">3</span></span><br></pre></td></tr></tbody></table></figure>

<p>然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 4 进行取模，再根据各自的模数结果，就可以被映射到哈希槽 1（对应节点1） 和 哈希槽 2（对应节点2）。</p>
<p>需要注意的是，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。</p>
<h4 id="一个最基本的-Redis-Cluster-架构是怎样的"><a href="#一个最基本的-Redis-Cluster-架构是怎样的" class="headerlink" title="一个最基本的 Redis Cluster 架构是怎样的?"></a><strong>一个最基本的 Redis Cluster 架构是怎样的?</strong></h4><p>为了保证高可用，Redis Cluster 至少需要 3 个 master 以及 3 个 slave，也就是说<strong>每个 master 必须有 1个 slave</strong>。master 和 slave 之间做<strong>主从复制</strong>，slave 会实时同步 master 上的数据。<br> 不同于普通的 Redis 主从架构，这里的 slave 不对外提供读服务，主要用来保障 master 的高可用，当master 出现故障的时候替代它。</p>
<p>如果 master 有多个 slave 的话，Redis Cluster 中的其他节点会从这个 master 的所有 slave 中选出一 个替代 master 继续提供服务。Redis Cluster 总是希望数据最完整的 slave 被提升为新的 master。</p>
<p>**Redis Cluster 是去中心化的(各个节点基于 Gossip 进行通信)**，任何一个 master 出现故障，其它的 master 节点不受影响，因为 key 找的是哈希槽而不是 Redis 节点。不过，Redis Cluster 至少要保证宕 机的 master 有一个 slave 可用。				 		</p>
<p><img src="/../pic/Snipaste_2024-04-02_15-10-54.png"></p>
<h4 id="Redis-Cluster-扩容和缩容本质是进行重新分片，动态迁移哈希槽。"><a href="#Redis-Cluster-扩容和缩容本质是进行重新分片，动态迁移哈希槽。" class="headerlink" title="Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。"></a><strong>Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。</strong></h4><p>为了保证 Redis Cluster 在扩容和缩容期间依然能够对外正常提供服务，Redis Cluster 提供了重定向机制，两种不同的类型:</p>
<ul>
<li><p>ASK 重定向</p>
<p><img src="/../pic/Snipaste_2024-04-02_15-22-42.png"></p>
<p> ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息</p>
</li>
<li><p>MOVED 重定向。</p>
<p>如果客户端请求的 key 对应的哈希槽应该迁移完成的话，就会返回 -MOVED 重定向错误，告知客户端当 前哈希槽是由哪个节点负责，<strong>客户端向目标节点发送请求并更新缓存的哈希槽分配信息</strong>。</p>
</li>
</ul>
<h4 id="Redis-Cluster中的节点是怎么进行通信的"><a href="#Redis-Cluster中的节点是怎么进行通信的" class="headerlink" title="Redis Cluster中的节点是怎么进行通信的?"></a><strong>Redis Cluster中的节点是怎么进行通信的?</strong></h4><p>Redis Cluster 中的各个节点基于 <strong>Gossip</strong> <strong>协议</strong> 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。</p>
<p>Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可 以自动切换。</p>
<h3 id="集群脑裂导致数据丢失怎么办？"><a href="#集群脑裂导致数据丢失怎么办？" class="headerlink" title="集群脑裂导致数据丢失怎么办？"></a>集群脑裂导致数据丢失怎么办？</h3><h4 id="什么是脑裂？"><a href="#什么是脑裂？" class="headerlink" title="什么是脑裂？"></a>什么是脑裂？</h4><p>总结：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p>
<p><strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。</p>
<p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong></p>
<h2 id="Redis-过期删除与内存淘汰"><a href="#Redis-过期删除与内存淘汰" class="headerlink" title="Redis 过期删除与内存淘汰"></a>Redis 过期删除与内存淘汰</h2><h3 id="Redis-的过期删除策略"><a href="#Redis-的过期删除策略" class="headerlink" title="Redis 的过期删除策略"></a>Redis 的过期删除策略</h3><p>Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。</p>
<p>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。</p>
<p>当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p>
<ul>
<li>如果不在，则正常读取键值；</li>
<li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</li>
</ul>
<p>Redis 使用的过期删除策略是「<strong>惰性删除+定期删除</strong>」这两种策略配和使用。</p>
<h4 id="惰性删除策略"><a href="#惰性删除策略" class="headerlink" title="惰性删除策略"></a>惰性删除策略</h4><p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></p>
<p>惰性删除策略的<strong>优点</strong>：</p>
<ul>
<li>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</li>
</ul>
<p>惰性删除策略的<strong>缺点</strong>：</p>
<ul>
<li>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。</li>
</ul>
<img src="../pic/惰性删除.jpg" style="zoom:40%;">

<h4 id="定期删除策略"><a href="#定期删除策略" class="headerlink" title="定期删除策略"></a>定期删除策略</h4><p>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p>
<p>Redis 的定期删除的流程：</p>
<ol>
<li>从过期字典中随机抽取 20 个 key；</li>
<li>检查这 20 个 key 是否过期，并删除已过期的 key；</li>
<li>如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li>
</ol>
<p>可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</p>
<p>定期删除策略的<strong>优点</strong>：</p>
<ul>
<li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li>
</ul>
<p>定期删除策略的<strong>缺点</strong>：</p>
<ul>
<li>难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。</li>
</ul>
<img src="../pic/定时删除流程.jpg" alt="img" style="zoom:40%;">

<p>可以看到，惰性删除策略和定期删除策略都有各自的优点，所以 <strong>Redis 选择「惰性删除+定期删除」这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。</p>
<h4 id="Redis-持久化时，对过期键会如何处理的？"><a href="#Redis-持久化时，对过期键会如何处理的？" class="headerlink" title="Redis 持久化时，对过期键会如何处理的？"></a>Redis 持久化时，对过期键会如何处理的？</h4><p>Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。</p>
<p>RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。</p>
<ul>
<li><strong>RDB 文件生成阶段</strong>：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键「不会」被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li>
<li>RDB 加载阶段：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：<ul>
<li><strong>如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li>
<li><strong>如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。</li>
</ul>
</li>
</ul>
<p>AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。</p>
<ul>
<li><strong>AOF 文件写入阶段</strong>：当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li>
<li><strong>AOF 重写阶段</strong>：执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。</li>
</ul>
<h4 id="Redis-主从模式中，对过期键会如何处理？"><a href="#Redis-主从模式中，对过期键会如何处理？" class="headerlink" title="Redis 主从模式中，对过期键会如何处理？"></a>Redis 主从模式中，对过期键会如何处理？</h4><p>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p>
<p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p>
<h3 id="Redis-内存淘汰策略有哪些？"><a href="#Redis-内存淘汰策略有哪些？" class="headerlink" title="Redis 内存淘汰策略有哪些？"></a>Redis 内存淘汰策略有哪些？</h3><p>虽然redis的确是不断的删除一些过期数据，但是很多没有设置过期时间的数据也会越来越多，那么redis内存不够用的时候是怎么处理的呢？这里我们就会谈到淘汰策略。</p>
<p>==当redis的内存<strong>超过最大允许的内存</strong>之后，Redis会触发内存淘汰策略，删除一些不常用的数据，以保证redis的正常运行==</p>
<p>Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。</p>
<p><em><strong>1、不进行数据淘汰的策略</strong></em></p>
<p><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。</p>
<p><em><strong>2、进行数据淘汰的策略</strong></em></p>
<p>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。 在设置了过期时间的数据中进行淘汰：</p>
<ul>
<li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li>
<li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li>
<li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li>
<li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li>
</ul>
<p>在所有数据范围内进行淘汰：</p>
<ul>
<li><strong>allkeys-random</strong>：随机淘汰任意键值;</li>
<li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li>
<li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li>
</ul>
<p>内存淘汰策略可以通过配置文件来修改，redis.conf对应的配置项是maxmemory-policy 修改对应的值就行，默认是noeviction</p>
<h2 id="缓存-重要"><a href="#缓存-重要" class="headerlink" title="缓存(重要)"></a>缓存(重要)</h2><h3 id="缓存读写策略有哪几种？"><a href="#缓存读写策略有哪几种？" class="headerlink" title="缓存读写策略有哪几种？"></a>缓存读写策略有哪几种？</h3><h4 id="Cache-Aside-Pattern（旁路缓存模式）"><a href="#Cache-Aside-Pattern（旁路缓存模式）" class="headerlink" title="Cache Aside Pattern（旁路缓存模式）"></a>Cache Aside Pattern（旁路缓存模式）</h4><p>写：</p>
<ul>
<li>先更新 db</li>
<li>然后直接删除 cache 。</li>
</ul>
<p>读：</p>
<ul>
<li>从 cache 中读取数据，读取到就直接返回</li>
<li>cache 中读取不到的话，就从 db 中读取数据返回</li>
<li>再把数据放到 cache 中。</li>
</ul>
<p><img src="/../pic/6e3db3ba2f829ddc14237f5c7c00e7ce-20230309232338149.png" alt="img"></p>
<p><strong>问题：</strong></p>
<ol>
<li><p><strong>在写数据的过程中，可以先删除 cache ，后更新 db 么？</strong></p>
<p>redis 速度要比 db 快，删 cache 和更新 db 中间可能会穿插读操作</p>
<p>假如使用了该方案可以用双删解决</p>
</li>
<li><p><strong>在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？</strong></p>
<p>发生情况概率很小，redis 速度要比 db 快。在缓存没有数据情况下，从 db 读数据和更新 cache 中穿插更新 db 操作</p>
</li>
</ol>
<p><img src="https://cdn.xiaolincoding.com//mysql/other/1cc7401143e79383ead96582ac11b615-20230309232407419.png" alt="img"></p>
<p><strong>Cache Aside 策略适合读多写少的场景，不适合写多的场景</strong></p>
<p><strong>Cache Aside Pattern 的缺陷</strong></p>
<p><strong>缺陷 1：首次请求数据一定不在 cache 的问题</strong></p>
<p>解决办法：可以将热点数据可以提前放入 cache 中。</p>
<p><strong>缺陷 2：写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 。</strong></p>
<p>解决办法：数据库和缓存数据强一致（加锁同步更新）</p>
<h4 id="Read-Write-Through-Pattern（读写穿透）"><a href="#Read-Write-Through-Pattern（读写穿透）" class="headerlink" title="Read/Write Through Pattern（读写穿透）"></a>Read/Write Through Pattern（读写穿透）</h4><p><strong>写（Write Through）：</strong></p>
<ul>
<li>先查 cache，cache 中不存在，直接更新 db。</li>
<li>cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（<strong>同步更新 cache 和 db</strong>）。</li>
</ul>
<p><img src="/../pic/write-through.png" alt="img"></p>
<p><strong>读(Read Through)：</strong></p>
<ul>
<li>从 cache 中读取数据，读取到就直接返回 。</li>
<li>读取不到的话，先从 db 加载，写入到 cache 后返回响应。</li>
</ul>
<p><img src="/../pic/read-through.png" alt="img"></p>
<p>问题：</p>
<p>和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。</p>
<h4 id="Write-Behind-Pattern（异步缓存写入）"><a href="#Write-Behind-Pattern（异步缓存写入）" class="headerlink" title="Write Behind Pattern（异步缓存写入）"></a>Write Behind Pattern（异步缓存写入）</h4><p><strong>Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。</strong></p>
<p><strong>Write Back 策略特别适合写多的场景</strong></p>
<p>问题：还没同步，缓存宕掉</p>
<p>使用场景：消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制</p>
<p>优势：db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。</p>
<h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p><strong>根本不存在于缓存中，也不存在于数据库中</strong> </p>
<img src="../pic/b7031182f770a7a5b3c82eaf749f53b0-20230309232834574.png" style="zoom:50%;">

<p>解决：</p>
<p><strong>1）缓存空值或者默认值</strong></p>
<p><strong>2）布隆过滤器(重要)</strong></p>
<p>布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成</p>
<p>布隆过滤器会通过 3 个操作完成标记：</p>
<ul>
<li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li>
<li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。</li>
<li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1；</li>
</ul>
<p><img src="/../pic/86b0046c2622b2c4bda697f9bc0f5b28.png"></p>
<p><strong>缺点</strong>：存在哈希冲突的可能性，判断可能存在，但是不一定存在；但判断不存在，一定不存在</p>
<p><strong>扩容：</strong>因为布隆过滤器的不可逆，我们没法重新建一个更大的布隆过滤器然后去把数据重新导入。这边采取的扩容的方法是，保留原有的布隆过滤器，建立一个更大的，<strong>新增数据都放在新的布隆过滤器中</strong>，去重的时候检查所有的布隆过滤器。</p>
<p><strong>3）非法请求限制</strong></p>
<p>在 API 入口处我们要判断求请求参数是否合理（请求参数是否含有非法值、请求字段是否存在）</p>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><img src="../pic/e2b8d2eb5536aa71664772457792ec40-20230309232851699.png" style="zoom:70%;">

<p><strong>缓存在同一时间大面积的失效或者redis宕机，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。</strong></p>
<img src="../pic/717343a0da7a1b05edab1d1cdf8f28e5.png" style="zoom:90%;">

<p><strong>针对大量缓存失效的情况：</strong></p>
<ol>
<li>设置不同的失效时间比如随机设置缓存的失效时间。</li>
<li>互斥锁，保证只有一个请求来构建缓存</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存</li>
</ol>
<p><strong>针对 Redis 故障宕机情况：</strong></p>
<ol>
<li>采用 Redis 集群。主从节点的方式，如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务</li>
<li>服务熔断。暂停业务应用对缓存服务的访问，直接返回错误</li>
<li>请求限流机制。只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务</li>
</ol>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>请求的 key 对应的是 <strong>热点数据</strong> ，该数据 <strong>存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）</strong></p>
<img src="../pic/acb5f4e7ef24a524a53c39eb016f63d4-20230309232840753.png" style="zoom:50%;">

<p>可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。</p>
<p>解决：</p>
<ol>
<li>不给热点数据设置过期时间，由后台异步更新缓存</li>
<li>请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。</li>
</ol>
<h3 id="数据库和缓存如何保证一致性？"><a href="#数据库和缓存如何保证一致性？" class="headerlink" title="数据库和缓存如何保证一致性？"></a>数据库和缓存如何保证一致性？</h3><p>1）先更新数据库，再更新缓存；先更新缓存，再更新数据库</p>
<p><strong>当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象</strong></p>
<p>2）先更新数据库，还是先删除缓存？</p>
<p><strong>Cache Aside 策略</strong>：先更新数据库，再删除缓存</p>
<p>当出现读-更新-删，会出现不一致。但出现不一致的概率低，<strong>因为缓存的写入通常要远远快于数据库的写入</strong>，</p>
<img src="../pic/1cc7401143e79383ead96582ac11b615.png" style="zoom:67%;">

<p>所以，<strong>「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的</strong>。同时可以还给缓存数据加上了「<strong>过期时间</strong>」来兜底，达到最终一致。</p>
<p>但是更新数据库和删除缓存不能保证两个操作都执行成功，也就会需要用到过期时间来兜底，这个中间会存在不一致性。</p>
<img src="../pic/2a2ea2854bbc3ae8ae86d7da45fa32ee.png" style="zoom:67%;">

<p>解决方法：</p>
<ul>
<li><p>重试机制。</p>
<p>引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。</p>
<p><img src="/../pic/a4440f0d572612e0832b903e4a62bd2b.png"></p>
</li>
<li><p>订阅 MySQL binlog，再操作缓存</p>
</li>
</ul>
<p>两种方法都是<strong>采用异步操作缓存</strong></p>
<h3 id="为什么是删除缓存，而不是更新缓存呢？"><a href="#为什么是删除缓存，而不是更新缓存呢？" class="headerlink" title="为什么是删除缓存，而不是更新缓存呢？"></a>为什么是删除缓存，而不是更新缓存呢？</h3><p>删除一个数据，相比更新一个数据更加<strong>轻量级</strong>，出问题的概率更小。在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。</p>
<p>系统设计中有一个思想叫 <strong>Lazy Loading</strong>，适用于那些加载代价大的操作，删除缓存而不是更新缓存，就是懒加载思想的一个应用。</p>
<h2 id="Redis-应用"><a href="#Redis-应用" class="headerlink" title="Redis 应用"></a>Redis 应用</h2><h3 id="基于-Redis-实现分布式锁"><a href="#基于-Redis-实现分布式锁" class="headerlink" title="基于 Redis 实现分布式锁"></a>基于 Redis 实现分布式锁</h3><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><ol>
<li><p>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p>
<ul>
<li><p>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</p>
</li>
<li><p>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</p>
</li>
</ul>
</li>
<li><p>用 EX 参数设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放</p>
</li>
<li><p>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET lock_key unique_value NX PX 10000 </span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>lock_key 就是 key 键；</li>
<li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；</li>
<li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；</li>
<li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁</li>
</ul>
<p>基于 Redis 实现分布式锁的<strong>优点</strong>：</p>
<ol>
<li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。</li>
<li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。</li>
<li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</li>
</ol>
<p>基于 Redis 实现分布式锁的<strong>缺点</strong>：</p>
<ul>
<li><p>超时时间不好设置</p>
<p>。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。</p>
<ul>
<li><strong>那么如何合理设置超时时间呢？</strong> 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</li>
</ul>
</li>
<li><p><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</p>
</li>
</ul>
<h4 id="单机redis挂了怎么办，主从集群如何保证分布式锁"><a href="#单机redis挂了怎么办，主从集群如何保证分布式锁" class="headerlink" title="单机redis挂了怎么办，主从集群如何保证分布式锁"></a>单机redis挂了怎么办，主从集群如何保证分布式锁</h4><p><strong>RedLock</strong> 是对集群的每个节点进行加锁，如果大多数节点（N/2+1）加锁成功，则才会认为加锁成功。</p>
<p>这样即使集群中有某个节点挂掉了，因为大部分集群节点都加锁成功了，所以分布式锁还是可以继续使用的。</p>
<p><strong>存在问题</strong></p>
<p>RedLock 主要存在以下两个问题：</p>
<ol>
<li><strong>性能问题</strong>：RedLock 要等待大多数节点返回之后，才能加锁成功，而这个过程中可能会因为网络问题，或节点超时的问题，影响加锁的性能。</li>
<li><strong>并发安全性问题</strong>：当客户端加锁时，如果遇到 GC 可能会导致加锁失效，但 GC 后误认为加锁成功的安全事故，例如以下流程：</li>
<li>客户端 A 请求 3 个节点进行加锁。</li>
<li>在节点回复处理之前，客户端 A 进入 GC 阶段（存在 STW，全局停顿）。</li>
<li>之后因为加锁时间的原因，锁已经失效了。</li>
<li>客户端 B 请求加锁（和客户端 A 是同一把锁），加锁成功。</li>
<li>客户端 A GC 完成，继续处理前面节点的消息，误以为加锁成功。</li>
<li>此时客户端 B 和客户端 A 同时加锁成功，出现并发安全性问题。</li>
</ol>
<h4 id="其余的分布式锁的实现"><a href="#其余的分布式锁的实现" class="headerlink" title="其余的分布式锁的实现"></a>其余的分布式锁的实现</h4><p><strong>基于数据库实现分布式锁</strong>：主要是利用数据库的唯一索引来实现，唯一索引天然具有排他性，这刚好符合我们对锁的要求：同一时刻只能允许一个竞争者获取锁。加锁时我们在数据库中插入一条锁记录，利用业务id进行防重。当第一个竞争者加锁成功后，第二个竞争者再来加锁就会抛出唯一索引冲突，如果抛出这个异常，我们就判定当前竞争者加锁失败。防重业务id需要我们自己来定义，例如我们的锁对象是一个方法，则我们的业务防重id就是这个方法的名字，如果锁定的对象是一个类，则业务防重id就是这个类名。</p>
<p><strong>基于Zookeeper</strong>：Zookeeper一般用作配置中心，其实现分布式锁的原理和Redis类似，我们在Zookeeper中创建==瞬时节点==，利用节点不能重复创建的特性来保证排他性。</p>
<h3 id="基于Redis实现延时任务"><a href="#基于Redis实现延时任务" class="headerlink" title="基于Redis实现延时任务"></a>基于Redis实现延时任务</h3><p>两种方案：</p>
<ol>
<li>Redis 过期事件监听</li>
<li>Redisson 内置的延时队列</li>
</ol>
<h4 id="Redis-过期事件监听实现延时任务功能的原理？"><a href="#Redis-过期事件监听实现延时任务功能的原理？" class="headerlink" title="Redis 过期事件监听实现延时任务功能的原理？"></a>Redis 过期事件监听实现延时任务功能的原理？</h4><p>发布订阅 (pub/sub) 功能。在 pub/sub 中，引入了一个叫做 <strong>channel（频道）</strong> 的概念，有点类似于消息队列中的 <strong>topic（主题）</strong>。</p>
<p>在 pub/sub 模式下，生产者需要指定消息发送到哪个 channel 中，而消费者则订阅对应的 channel 以获取消息。</p>
<p>Redis 中有很多默认的 channel，这些 channel 是由 Redis 本身向它们发送消息的，而不是我们自己编写的代码。其中，<code>__keyevent@0__:expired</code> 就是一个默认的 channel，负责监听 key 的过期事件。也就是说，当一个 key 过期之后，Redis 会发布一个 key 过期的事件到<code>__keyevent@&lt;db&gt;__:expired</code>这个 channel 中。</p>
<p>我们只需要监听这个 channel，就可以拿到过期的 key 的消息，进而实现了延时任务功能。</p>
<h4 id="Redis-过期事件监听实现延时任务功能有什么缺陷？"><a href="#Redis-过期事件监听实现延时任务功能有什么缺陷？" class="headerlink" title="Redis 过期事件监听实现延时任务功能有什么缺陷？"></a>Redis 过期事件监听实现延时任务功能有什么缺陷？</h4><p><strong>1、时效性差</strong>：过期事件消息是在 Redis 服务器删除 key 时发布的，而不是一个 key 过期之后就会就会直接发布。因此，就会存在我设置了 key 的过期时间，但到了指定时间 key 还未被删除，进而没有发布过期事件的情况。</p>
<p><strong>2、丢消息</strong>：Redis 的 pub/sub 模式中的消息并不支持持久化，这与消息队列不同</p>
<p><strong>3、多服务实例下消息重复消费</strong>：Redis 的 pub/sub 模式目前只有广播模式，这意味着当生产者向特定频道发布一条消息时，所有订阅相关频道的消费者都能够收到该消息。</p>
<h4 id="Redisson-延迟队列原理是什么？有什么优势？"><a href="#Redisson-延迟队列原理是什么？有什么优势？" class="headerlink" title="Redisson 延迟队列原理是什么？有什么优势？"></a>Redisson 延迟队列原理是什么？有什么优势？</h4><p>Redisson 的延迟队列 RDelayedQueue 是基于 Redis 的 SortedSet 来实现的。SortedSet 是一个有序集合，其中的每个元素都可以设置一个分数，代表该元素的权重。Redisson 利用这一特性，将需要延迟执行的任务插入到 SortedSet 中，并给它们设置相应的过期时间作为分数。</p>
<p>优势：</p>
<p><strong>减少了丢消息的可能</strong>：DelayedQueue 中的消息会被持久化，即使 Redis 宕机了，根据持久化机制，也只可能丢失一点消息，影响不大。当然了，你也可以使用扫描数据库的方法作为补偿机制。</p>
<p><strong>消息不存在重复消费问题</strong>：每个客户端都是从同一个目标队列中获取任务的，不存在重复消费的问题。</p>
<h3 id="大-key-如何处理"><a href="#大-key-如何处理" class="headerlink" title="大 key 如何处理"></a>大 key 如何处理</h3><h4 id="什么是-Redis-大-key"><a href="#什么是-Redis-大-key" class="headerlink" title="什么是 Redis 大 key"></a>什么是 Redis 大 key</h4><p>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p>
<p>一般而言，下面这两种情况被称为大 key：</p>
<ul>
<li>String 类型的值大于 10 KB；</li>
<li>Hash、List、Set、ZSet 类型的元素的个数超过 5000个；</li>
</ul>
<h4 id="大-key-问题"><a href="#大-key-问题" class="headerlink" title="大 key 问题"></a>大 key 问题</h4><ul>
<li><strong>客户端超时阻塞</strong>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li><strong>引发网络阻塞</strong>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li><strong>阻塞工作线程</strong>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li><strong>内存分布不均</strong>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
<h4 id="大-key-如何产生"><a href="#大-key-如何产生" class="headerlink" title="大 key 如何产生"></a>大 key 如何产生</h4><ol>
<li>一直往 value 塞数据，没有删除机制</li>
<li>没有合理做分片，将大 key 变小 key</li>
</ol>
<h4 id="如何找到大-key"><a href="#如何找到大-key" class="headerlink" title="如何找到大 key"></a>如何找到大 key</h4><p>1、redis-cli –bigkeys 查找大key</p>
<p>2、使用 SCAN 命令查找大 key</p>
<p>3、使用 RdbTools 工具查找大 key</p>
<h4 id="解决大-key-问题"><a href="#解决大-key-问题" class="headerlink" title="解决大 key 问题"></a>解决大 key 问题</h4><p><img src="/../pic/v2-003cd3f411cfb65f60fdd31219ad4a9c_1440w.webp" alt="img"></p>
<p><strong>删除大 key</strong></p>
<ol>
<li>unlink 异步惰性非阻塞删除</li>
<li>scan 游标式迭代扫描删除</li>
</ol>
<p><strong>压缩和拆分 key</strong></p>
<ol>
<li>对于 string采用序列化、压缩算法</li>
<li>对于 string 压缩后还是大 key，则进行拆分，使用 multiget 实现事务读取</li>
<li>对于 list/set 等集合，进行分片</li>
</ol>
<h3 id="Redis-管道有什么用？"><a href="#Redis-管道有什么用？" class="headerlink" title="Redis 管道有什么用？"></a>Redis 管道有什么用？</h3><p>管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。</p>
<p>使用<strong>管道技术可以解决多个命令执行时的网络等待</strong>，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。</p>
<p>但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞。</p>
<p>要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。</p>
<h2 id="Redis-事务"><a href="#Redis-事务" class="headerlink" title="Redis 事务"></a>Redis 事务</h2><h3 id="Redis事务的概念"><a href="#Redis事务的概念" class="headerlink" title="Redis事务的概念"></a>Redis事务的概念</h3><p>事务提供了一种将多个命令打包，然后<strong>一次性、有序地执行</strong>的机制。</p>
<p>多个命令会被人队到事务队列中， 然后按<strong>先进先出(FIFO)的顺序执行。</strong></p>
<p>事务在执行过程中<strong>不会被中断</strong>，当事务队列中的所有命令都被执行完毕之后，事务才会结束。</p>
<p>Redis事务不支持回滚机制。</p>
<p>Redis 事务没有原子性 有持久性和一致性 至于隔离性, 都不存在多个事务的情况 毕竟单线程</p>
<h3 id="Redis事务没有隔离级别"><a href="#Redis事务没有隔离级别" class="headerlink" title="Redis事务没有隔离级别"></a>Redis事务没有隔离级别</h3><p>批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。</p>
<h3 id="Redis事务不保证原子性"><a href="#Redis事务不保证原子性" class="headerlink" title="Redis事务不保证原子性"></a>Redis事务不保证原子性</h3><p>Redis中，单条命令是原子性执行的，但<code>事务不保证原子性，且没有回滚</code>。事务中任意命令执行失败，其余的命令仍会被执行。</p>
<h3 id="Redis事务的三个阶段"><a href="#Redis事务的三个阶段" class="headerlink" title="Redis事务的三个阶段"></a>Redis事务的三个阶段</h3><p>（1）开始事务</p>
<p>（2）命令入队</p>
<p>（3）执行事务</p>
<h3 id="Redis事务命令"><a href="#Redis事务命令" class="headerlink" title="Redis事务命令"></a>Redis事务命令</h3><p><img src="/../pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p>
<h3 id="Redis事务案例"><a href="#Redis事务案例" class="headerlink" title="Redis事务案例"></a>Redis事务案例</h3><p><strong>正常执行</strong></p>
<p><img src="/../pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201509175.png" alt="在这里插入图片描述"></p>
<p><strong>放弃事务</strong></p>
<p><img src="/../pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201514331.png" alt="在这里插入图片描述"></p>
<p><strong>全体连坐</strong></p>
<p>在事务队列中存在命令性错误（类似于java编译性错误），则执行EXEC命令时，所有命令都不会执行。</p>
<p>比如 命令写错</p>
<p><strong>冤头债主</strong></p>
<p>在事务队列中存在语法性错误（类似于java的1/0的运行时异常），则执行EXEC命令时，其他正确命令会被执行，错误命令抛出异常。</p>
<p>比如 对 string incr</p>
<p><img src="/../pic/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70-20240403201528651.png" alt="在这里插入图片描述"></p>
<p><strong>使用watch</strong></p>
<p>案例一：使用watch检测balance，事务期间balance数据未变动，事务执行成功。</p>
<p>案例二：使用watch检测balance，在开启事务后（标注1处），在新窗口执行标注2中的操作，更改balance的值，模拟其他客户端在事务执行期间更改watch监控的数据，然后再执行标注1后命令，执行EXEC后，事务未成功执行。<img src="https://img-blog.csdnimg.cn/20200723213200990.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUyMDQ1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>一但执行 EXEC 开启事务的执行后，无论事务使用执行成功， WARCH 对变量的监控都将被取消。故<code>当事务执行失败后，需重新执行WATCH命令对变量进行监控，并开启新的事务进行操作。</code></p>
</body></html></div><div class="article-licensing box"><div class="licensing-title"><p>Redis</p><p><a href="https://jerryzhu1229.github.io/2024/03/14/Redis/">https://jerryzhu1229.github.io/2024/03/14/Redis/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Jerry Z</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-03-14</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-04-13</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/redis/">redis</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/03/12/Spring/"><span class="level-item">Spring</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Redis-基础"><span class="level-left"><span class="level-item">1</span><span class="level-item">Redis 基础</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#什么是-Redis"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">什么是 Redis</span></span></a></li><li><a class="level is-mobile" href="#为什么要用-Redis-为什么要用缓存？"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">为什么要用 Redis/为什么要用缓存？</span></span></a></li><li><a class="level is-mobile" href="#Redis-单线程模式是怎样的？"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Redis 单线程模式是怎样的？</span></span></a></li><li><a class="level is-mobile" href="#Redis-采用单线程为什么还这么快？"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Redis 采用单线程为什么还这么快？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Redis-数据结构"><span class="level-left"><span class="level-item">2</span><span class="level-item">Redis 数据结构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Redis-数据类型以及使用场景分别是什么？"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Redis 数据类型以及使用场景分别是什么？</span></span></a></li><li><a class="level is-mobile" href="#常见的-Redis-数据类型是怎么实现？"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">常见的 Redis 数据类型是怎么实现？</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#String-类型内部实现"><span class="level-left"><span class="level-item">2.2.1</span><span class="level-item">String 类型内部实现</span></span></a></li><li><a class="level is-mobile" href="#List-类型内部实现"><span class="level-left"><span class="level-item">2.2.2</span><span class="level-item">List 类型内部实现</span></span></a></li><li><a class="level is-mobile" href="#Hash-类型内部实现"><span class="level-left"><span class="level-item">2.2.3</span><span class="level-item">Hash 类型内部实现</span></span></a></li><li><a class="level is-mobile" href="#Set-类型内部实现"><span class="level-left"><span class="level-item">2.2.4</span><span class="level-item">Set 类型内部实现</span></span></a></li><li><a class="level is-mobile" href="#ZSet-类型内部实现（重要）"><span class="level-left"><span class="level-item">2.2.5</span><span class="level-item">ZSet 类型内部实现（重要）</span></span></a></li></ul></li><li><a class="level is-mobile" href="#底层数据结构"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">底层数据结构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#ziplist"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">ziplist</span></span></a></li><li><a class="level is-mobile" href="#quicklist"><span class="level-left"><span class="level-item">2.3.2</span><span class="level-item">quicklist</span></span></a></li><li><a class="level is-mobile" href="#listpack"><span class="level-left"><span class="level-item">2.3.3</span><span class="level-item">listpack</span></span></a></li></ul></li><li><a class="level is-mobile" href="#为什么用跳表实现有序集合"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">为什么用跳表实现有序集合</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#跳表的建立"><span class="level-left"><span class="level-item">2.4.1</span><span class="level-item">跳表的建立</span></span></a></li><li><a class="level is-mobile" href="#跳表节点查询"><span class="level-left"><span class="level-item">2.4.2</span><span class="level-item">跳表节点查询</span></span></a></li><li><a class="level is-mobile" href="#跳表节点层数设置"><span class="level-left"><span class="level-item">2.4.3</span><span class="level-item">跳表节点层数设置</span></span></a></li><li><a class="level is-mobile" href="#和其余三种数据结构的比较"><span class="level-left"><span class="level-item">2.4.4</span><span class="level-item">和其余三种数据结构的比较</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Redis-持久化"><span class="level-left"><span class="level-item">3</span><span class="level-item">Redis 持久化</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#AOF-日志是如何实现的？"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">AOF 日志是如何实现的？</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#为什么先执行命令，再把数据写入日志呢？"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">为什么先执行命令，再把数据写入日志呢？</span></span></a></li><li><a class="level is-mobile" href="#AOF-写回策略有几种？"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">AOF 写回策略有几种？</span></span></a></li><li><a class="level is-mobile" href="#AOF-日志过大，会触发什么机制？"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">AOF 日志过大，会触发什么机制？</span></span></a></li><li><a class="level is-mobile" href="#重写-AOF-日志的过程是怎样的？"><span class="level-left"><span class="level-item">3.1.4</span><span class="level-item">重写 AOF 日志的过程是怎样的？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#RDB-快照是如何实现的呢？"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">RDB 快照是如何实现的呢？</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#RDB-做快照时会阻塞线程吗？"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">RDB 做快照时会阻塞线程吗？</span></span></a></li><li><a class="level is-mobile" href="#RDB-快照缺点"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">RDB 快照缺点</span></span></a></li><li><a class="level is-mobile" href="#RDB-在执行快照的时候，数据能修改吗？"><span class="level-left"><span class="level-item">3.2.3</span><span class="level-item">RDB 在执行快照的时候，数据能修改吗？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#为什么会有混合持久化？"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">为什么会有混合持久化？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Redis-集群-高可用"><span class="level-left"><span class="level-item">4</span><span class="level-item">Redis 集群/高可用</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#主从复制"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">主从复制</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#全量复制"><span class="level-left"><span class="level-item">4.1.1</span><span class="level-item">全量复制</span></span></a></li><li><a class="level is-mobile" href="#基于长连接的命令传播"><span class="level-left"><span class="level-item">4.1.2</span><span class="level-item">基于长连接的命令传播</span></span></a></li><li><a class="level is-mobile" href="#增量复制"><span class="level-left"><span class="level-item">4.1.3</span><span class="level-item">增量复制</span></span></a></li><li><a class="level is-mobile" href="#怎么判断-Redis-某个节点是否正常工作？"><span class="level-left"><span class="level-item">4.1.4</span><span class="level-item">怎么判断 Redis 某个节点是否正常工作？</span></span></a></li><li><a class="level is-mobile" href="#主从复制架构中，过期key如何处理？"><span class="level-left"><span class="level-item">4.1.5</span><span class="level-item">主从复制架构中，过期key如何处理？</span></span></a></li><li><a class="level is-mobile" href="#Redis-是同步复制还是异步复制？"><span class="level-left"><span class="level-item">4.1.6</span><span class="level-item">Redis 是同步复制还是异步复制？</span></span></a></li><li><a class="level is-mobile" href="#主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？"><span class="level-left"><span class="level-item">4.1.7</span><span class="level-item">主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#哨兵模式"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">哨兵模式</span></span></a></li><li><a class="level is-mobile" href="#Redis-Cluster切片集群模式"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Redis Cluster切片集群模式</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Redis-Cluster-是如何分片的"><span class="level-left"><span class="level-item">4.3.1</span><span class="level-item">Redis Cluster 是如何分片的?</span></span></a></li><li><a class="level is-mobile" href="#一个最基本的-Redis-Cluster-架构是怎样的"><span class="level-left"><span class="level-item">4.3.2</span><span class="level-item">一个最基本的 Redis Cluster 架构是怎样的?</span></span></a></li><li><a class="level is-mobile" href="#Redis-Cluster-扩容和缩容本质是进行重新分片，动态迁移哈希槽。"><span class="level-left"><span class="level-item">4.3.3</span><span class="level-item">Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。</span></span></a></li><li><a class="level is-mobile" href="#Redis-Cluster中的节点是怎么进行通信的"><span class="level-left"><span class="level-item">4.3.4</span><span class="level-item">Redis Cluster中的节点是怎么进行通信的?</span></span></a></li></ul></li><li><a class="level is-mobile" href="#集群脑裂导致数据丢失怎么办？"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">集群脑裂导致数据丢失怎么办？</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#什么是脑裂？"><span class="level-left"><span class="level-item">4.4.1</span><span class="level-item">什么是脑裂？</span></span></a></li><li><a class="level is-mobile" href="#解决方案"><span class="level-left"><span class="level-item">4.4.2</span><span class="level-item">解决方案</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Redis-过期删除与内存淘汰"><span class="level-left"><span class="level-item">5</span><span class="level-item">Redis 过期删除与内存淘汰</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Redis-的过期删除策略"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">Redis 的过期删除策略</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#惰性删除策略"><span class="level-left"><span class="level-item">5.1.1</span><span class="level-item">惰性删除策略</span></span></a></li><li><a class="level is-mobile" href="#定期删除策略"><span class="level-left"><span class="level-item">5.1.2</span><span class="level-item">定期删除策略</span></span></a></li><li><a class="level is-mobile" href="#Redis-持久化时，对过期键会如何处理的？"><span class="level-left"><span class="level-item">5.1.3</span><span class="level-item">Redis 持久化时，对过期键会如何处理的？</span></span></a></li><li><a class="level is-mobile" href="#Redis-主从模式中，对过期键会如何处理？"><span class="level-left"><span class="level-item">5.1.4</span><span class="level-item">Redis 主从模式中，对过期键会如何处理？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Redis-内存淘汰策略有哪些？"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">Redis 内存淘汰策略有哪些？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#缓存-重要"><span class="level-left"><span class="level-item">6</span><span class="level-item">缓存(重要)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#缓存读写策略有哪几种？"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">缓存读写策略有哪几种？</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Cache-Aside-Pattern（旁路缓存模式）"><span class="level-left"><span class="level-item">6.1.1</span><span class="level-item">Cache Aside Pattern（旁路缓存模式）</span></span></a></li><li><a class="level is-mobile" href="#Read-Write-Through-Pattern（读写穿透）"><span class="level-left"><span class="level-item">6.1.2</span><span class="level-item">Read/Write Through Pattern（读写穿透）</span></span></a></li><li><a class="level is-mobile" href="#Write-Behind-Pattern（异步缓存写入）"><span class="level-left"><span class="level-item">6.1.3</span><span class="level-item">Write Behind Pattern（异步缓存写入）</span></span></a></li></ul></li><li><a class="level is-mobile" href="#缓存穿透"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">缓存穿透</span></span></a></li><li><a class="level is-mobile" href="#缓存雪崩"><span class="level-left"><span class="level-item">6.3</span><span class="level-item">缓存雪崩</span></span></a></li><li><a class="level is-mobile" href="#缓存击穿"><span class="level-left"><span class="level-item">6.4</span><span class="level-item">缓存击穿</span></span></a></li><li><a class="level is-mobile" href="#数据库和缓存如何保证一致性？"><span class="level-left"><span class="level-item">6.5</span><span class="level-item">数据库和缓存如何保证一致性？</span></span></a></li><li><a class="level is-mobile" href="#为什么是删除缓存，而不是更新缓存呢？"><span class="level-left"><span class="level-item">6.6</span><span class="level-item">为什么是删除缓存，而不是更新缓存呢？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Redis-应用"><span class="level-left"><span class="level-item">7</span><span class="level-item">Redis 应用</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#基于-Redis-实现分布式锁"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">基于 Redis 实现分布式锁</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#实现"><span class="level-left"><span class="level-item">7.1.1</span><span class="level-item">实现</span></span></a></li><li><a class="level is-mobile" href="#单机redis挂了怎么办，主从集群如何保证分布式锁"><span class="level-left"><span class="level-item">7.1.2</span><span class="level-item">单机redis挂了怎么办，主从集群如何保证分布式锁</span></span></a></li><li><a class="level is-mobile" href="#其余的分布式锁的实现"><span class="level-left"><span class="level-item">7.1.3</span><span class="level-item">其余的分布式锁的实现</span></span></a></li></ul></li><li><a class="level is-mobile" href="#基于Redis实现延时任务"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">基于Redis实现延时任务</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Redis-过期事件监听实现延时任务功能的原理？"><span class="level-left"><span class="level-item">7.2.1</span><span class="level-item">Redis 过期事件监听实现延时任务功能的原理？</span></span></a></li><li><a class="level is-mobile" href="#Redis-过期事件监听实现延时任务功能有什么缺陷？"><span class="level-left"><span class="level-item">7.2.2</span><span class="level-item">Redis 过期事件监听实现延时任务功能有什么缺陷？</span></span></a></li><li><a class="level is-mobile" href="#Redisson-延迟队列原理是什么？有什么优势？"><span class="level-left"><span class="level-item">7.2.3</span><span class="level-item">Redisson 延迟队列原理是什么？有什么优势？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#大-key-如何处理"><span class="level-left"><span class="level-item">7.3</span><span class="level-item">大 key 如何处理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#什么是-Redis-大-key"><span class="level-left"><span class="level-item">7.3.1</span><span class="level-item">什么是 Redis 大 key</span></span></a></li><li><a class="level is-mobile" href="#大-key-问题"><span class="level-left"><span class="level-item">7.3.2</span><span class="level-item">大 key 问题</span></span></a></li><li><a class="level is-mobile" href="#大-key-如何产生"><span class="level-left"><span class="level-item">7.3.3</span><span class="level-item">大 key 如何产生</span></span></a></li><li><a class="level is-mobile" href="#如何找到大-key"><span class="level-left"><span class="level-item">7.3.4</span><span class="level-item">如何找到大 key</span></span></a></li><li><a class="level is-mobile" href="#解决大-key-问题"><span class="level-left"><span class="level-item">7.3.5</span><span class="level-item">解决大 key 问题</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Redis-管道有什么用？"><span class="level-left"><span class="level-item">7.4</span><span class="level-item">Redis 管道有什么用？</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Redis-事务"><span class="level-left"><span class="level-item">8</span><span class="level-item">Redis 事务</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Redis事务的概念"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">Redis事务的概念</span></span></a></li><li><a class="level is-mobile" href="#Redis事务没有隔离级别"><span class="level-left"><span class="level-item">8.2</span><span class="level-item">Redis事务没有隔离级别</span></span></a></li><li><a class="level is-mobile" href="#Redis事务不保证原子性"><span class="level-left"><span class="level-item">8.3</span><span class="level-item">Redis事务不保证原子性</span></span></a></li><li><a class="level is-mobile" href="#Redis事务的三个阶段"><span class="level-left"><span class="level-item">8.4</span><span class="level-item">Redis事务的三个阶段</span></span></a></li><li><a class="level is-mobile" href="#Redis事务命令"><span class="level-left"><span class="level-item">8.5</span><span class="level-item">Redis事务命令</span></span></a></li><li><a class="level is-mobile" href="#Redis事务案例"><span class="level-left"><span class="level-item">8.6</span><span class="level-item">Redis事务案例</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/cs/"><span class="level-start"><span class="level-item">cs</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/java/"><span class="level-start"><span class="level-item">java</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"><span class="level-start"><span class="level-item">中间件</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/2751710164138_.pic.jpg" alt="hao" height="28"></a><p class="is-size-7"><span>&copy; 2024 Jerry Z</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>